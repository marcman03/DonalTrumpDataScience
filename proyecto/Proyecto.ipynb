{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pandas.set_option('display.max_columns', None)  \n",
    "pandas.set_option('display.expand_frame_repr', False)\n",
    "#pandas.set_option('max_colwidth', -1)\n",
    "pandas.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date      Time                                         Tweet_Text  Type Media_Type                    Hashtags   Tweet_Id                                          Tweet_Url  twt_favourites_IS_THIS_LIKE_QUESTION_MARK  Retweets  Unnamed: 10  Unnamed: 11\n",
      "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...  text      photo                   ThankAVet  7.970e+17  https://twitter.com/realDonaldTrump/status/797...                                     127213     41112          NaN          NaN\n",
      "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...  text        NaN                         NaN  7.970e+17  https://twitter.com/realDonaldTrump/status/797...                                     141527     28654          NaN          NaN\n",
      "2  16-11-11  11:14:20  Love the fact that the small groups of protest...  text        NaN                         NaN  7.970e+17  https://twitter.com/realDonaldTrump/status/797...                                     183729     50039          NaN          NaN\n",
      "3  16-11-11   2:19:44  Just had a very open and successful presidenti...  text        NaN                         NaN  7.970e+17  https://twitter.com/realDonaldTrump/status/796...                                     214001     67010          NaN          NaN\n",
      "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...  text        NaN                         NaN  7.970e+17  https://twitter.com/realDonaldTrump/status/796...                                     178499     36688          NaN          NaN\n",
      "5  16-11-10  19:31:27  Happy 241st birthday to the U.S. Marine Corps!...  text      photo                         NaN  7.970e+17  https://twitter.com/realDonaldTrump/status/796...                                     159176     44655          NaN          NaN\n",
      "6  16-11-09  11:36:58  Such a beautiful and important evening! The fo...  text        NaN                         NaN  7.960e+17  https://twitter.com/realDonaldTrump/status/796...                                     627615    225164          NaN          NaN\n",
      "7  16-11-09   2:48:27  Watching the returns at 9:45pm.\\n#ElectionNigh...  text      photo          ElectionNight;MAGA  7.960e+17  https://twitter.com/realDonaldTrump/status/796...                                     185160     45492          NaN          NaN\n",
      "8  16-11-09   1:35:15  RT @IvankaTrump: Such a surreal moment to vote...  text        NaN                         NaN  7.960e+17  https://twitter.com/realDonaldTrump/status/796...                                      99809     17169          NaN          NaN\n",
      "9  16-11-08  23:20:39  RT @EricTrump: Join my family in this incredib...  text        NaN  MakeAmericaGreatAgain;VOTE  7.960e+17  https://twitter.com/realDonaldTrump/status/796...                                      63868     19710          NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv('data.csv', sep=',', na_values=\"\")\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marcp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    today express deepest gratitud serv arm thankavet\n",
      "1    busi day plan new soon make import decis peopl...\n",
      "2    love fact small group protest last night passi...\n",
      "3      open success presidenti profession incit unfair\n",
      "4    fantast day met presid obama first realli good...\n",
      "Name: cleaned_tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "# Preparación de las herramientas de preprocesamiento de texto\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english')) \n",
    "sno = SnowballStemmer('english') \n",
    "\n",
    "def cleanhtml(sentence): \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "\n",
    "def cleanpunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return cleaned\n",
    "\n",
    "# Procesamiento del texto de los tweets\n",
    "final_string = []\n",
    "for sent in data['Tweet_Text'].values:\n",
    "    filtered_sentence = []\n",
    "    sent = cleanhtml(sent) \n",
    "    for w in sent.split():\n",
    "        cleaned_words = cleanpunc(w)\n",
    "        if cleaned_words.isalpha() and len(cleaned_words) > 2:\n",
    "            if cleaned_words.lower() not in stop:\n",
    "                stemmed_word = sno.stem(cleaned_words.lower())\n",
    "                filtered_sentence.append(stemmed_word)\n",
    "    final_string.append(\" \".join(filtered_sentence))\n",
    "\n",
    "# Añadiendo la columna de tweets limpios al DataFrame\n",
    "data['cleaned_tweet'] = final_string\n",
    "\n",
    "# Visualización de los primeros registros del DataFrame modificado\n",
    "print(data[\"cleaned_tweet\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    41112\n",
      "1    28654\n",
      "2    50039\n",
      "3    67010\n",
      "4    36688\n",
      "Name: Retweets, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Retweets\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "media_likes= data[\"twt_favourites_IS_THIS_LIKE_QUESTION_MARK\"].median()\n",
    "media_retweets=data[\"Retweets\"].median()\n",
    "data['Viral'] = data.apply(lambda x: \"mucho\" if (x['twt_favourites_IS_THIS_LIKE_QUESTION_MARK'] + x['Retweets']) >= (media_likes + media_retweets) * 3\n",
    "                       else (\"moderado\" if (x['twt_favourites_IS_THIS_LIKE_QUESTION_MARK'] + x['Retweets']) >= (media_likes + media_retweets)*0.5\n",
    "                             else \"poco\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viral\n",
      "moderado    3464\n",
      "poco        2272\n",
      "mucho       1639\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Viral\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (4221494962.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    X_train=cv.train_test_split(\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as cv\n",
    "X_train=cv.train_test_split(\n",
    "print('Size training: ',X_train.shape)\n",
    "print('Size test: ',X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
